<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Driver Profile | Sai Surya Vidul</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Chakra+Petch:wght@400;700&family=Syncopate:wght@700&display=swap" rel="stylesheet">
</head>
<body>
    <div id="lights-container">
        <div class="light"></div>
        <div class="light"></div>
        <div class="light"></div>
        <div class="light"></div>
        <div class="light"></div>
        <p class="status-text">WAIT FOR LIGHTS...</p>
    </div>

    <main id="main-content" class="hidden">
        <nav class="telemetry-nav">
            <div class="stat">DRV: <span>S. VIDUL CHINTHAMANENI</span></div>
            <div class="stat">TEAM: <span class="red">TASL @ UC RIVERSIDE</span></div>
            <div class="stat">CURRENT LAP TIME: <span id="clock">00:00:00</span></div>
        </nav>

        <section class="panel about-section">
            <div class="driver-card">
                <div class="driver-number">11</div>
                <div class="bio-text">
                    <h1 class="glitch" data-text="SAI SURYA VIDUL">SAI SURYA VIDUL CHINTHAMANENI</h1><p>
                        My race started in Hyderabad, earning a Bachelor’s in Electrical & Electronics Engineering at GRIET, before shifting gears to the international circuit at UC Riverside. Having graduated with a Master’s in Electrical Engineeringand a 3.82 GPA, I am LA based and focused on my core expertise in LLM/VLM fine-tuning, model inference, and evaluation. My research at the TASL Labinvolved architecting efficient reasoning frameworks for large-scale models to reduce computational latency. When I'm off the clock, you can find me watching F1, gaming, hitting the gym, or catching up on the latest anime. I leverage Python, PyTorch, and AWSto build AI solutions that are as high-performing as they are reliable.
                    </p>
                </div>
            </div>
        </section>

        <section class="panel history-full">
            <h2 class="panel-header">RACE HISTORY (WORK EXPERIENCE)</h2>
            
            <div class="history-item">
                <span class="year">MARCH 2025-PRESENT</span>
                <strong>TASL - Junior Specialist, Step I</strong><ul>
                    <li>Architected a computation-efficient Embodied AI framework for Object Goal Navigation using Python and PyTorch, significantly reducing computational latency by implementing a sparse-inference reasoning trigger for large Vision-Language Models (VLMs).</li>
                    <li>Engineered a hybrid two-stage training pipeline within the Habitat platform, integrating Imitation Learning (IL) for policy initialization and Reinforcement Learning (RL) for fine-tuning, while managing experiment tracking and hyperparameter optimization via Weights & Biases.</li>
                    <li>Developed an uncertainty aware reward-shaping framework using Conformal Prediction to calibrate semantic priors, utilizing Docker for environment reproducibility and OpenCV alongside Matplotlib to benchmark and visualize agent performance in complex, unseen environments.</li>
                </ul>
            </div>

            <div class="history-item">
                <span class="year">AUGUST 2022-APRIL 2023</span>
                <strong>PathFinder Info Solutions - Machine Learning Intern</strong><ul>
                    <li>Engineered a high-dimensional feature pipeline for a matching engine, processing 25K+ user profiles via SQL and Pandas to extract predictive mentor-mentee signals. Automated normalization for sparse user data to ensure robust and consistent model training inputs.</li>
                    <li>Boosted recommendation precision by 17% over heuristic baselines by tuning Random Forest and TF-IDF models using scikit-learn and GridSearchCV. Leveraged feature importance analysis to identify compatibility drivers, optimizing initial matching logic for new mentor profiles with zero session history.</li>
                    <li>Deployed an end-to-end Streamlit dashboard on AWS to visualize sentiment-adjusted outputs and validate weighted ranking logic. Integrated Git-based version control to facilitate rapid A/B testing of scoring algorithms and monitor real-time model performance.</li>
                </ul>
            </div>

            <div class="history-item">
                <span class="year">JANUARY 2022-JULY 2022</span>
                <strong>Gokul Power Electronics- Machine Learning Intern</strong><ul>
                    <li>Spearheaded time-series modeling for embedded water control systems to enable fault detection and predictive maintenance. Partnered with R&D in C to interpret control board outputs and optimize hardware-software sensor integration.</li>
                    <li>Engineered reproducible ETL pipelines via Pandas, and SQL to transform 60K+ operational records into structured, normalized datasets. Streamlined data preprocessing to ensure consistent feature engineering for end-to-end ML experimentation.</li>
                    <li>Applied K-Nearest Neighbors via scikit-learn and Z-score analysis using SciPy to extract critical failure signals from sensor logs. Leveraged Matplotlib for visual trend analysis to identify systemic bottlenecks, informing two hardware design improvements.</li>
                </ul>
            </div>
        </section>

        <div class="content-grid">
            <section class="panel education">
                <h2 class="panel-header">ACADEMIC BACKGROUND</h2>
                <div class="history-item">
                    <span class="year">SEPTEMBER 2023-JUNE 2025</span>
                    <strong>University of California - Riverside</strong><p>M.S. in Electrical Engineering</p>
                    <p class="red">GPA: 3.82</p>

                    <div class="course-telemetry">
                        <span class="label">RELEVANT COURSEWORK:</span>
                        <p>Pattern Recognition, Advanced Computer Vision, Large Models and Advances in AI, Introduction to Deep Learning, Introduction to Reinforcement Learning, Artificial Intelligence, Data Analytics and Exploration, Data Mining Techniques, Trustworthy AI for Autonomous Systems</p>
                    </div>
                </div>
                <div class="history-item">
                    <span class="year">AUGUST 2019-MAY 2023</span>
                    <strong>Jawaharlal Nehru Technological University - GRIET</strong><p>B.S. in Electrical and Electronics Engineering</p>
                    <p class="red">GPA: 3.39</p>
                </div>
            </section>

            <section class="panel stats">
                <h2 class="panel-header">TECHNICAL SPECS (PERFORMANCE DATA)</h2>
                <div class="stat-group">
                    <h4>CORE EXPERTISE</h4>
                    <p>LLM/VLM Fine-tuning (LoRA, RLHF), Model Inference, Evaluation, Computer Vision</p>
                </div>
                <div class="stat-group">
                    <h4>ENGINE / LANGUAGES</h4>
                    <p>Python, SQL, C</p>
                </div>
                <div class="stat-group">
                    <h4>CHASSIS / TOOLS</h4>
                    <p>PyTorch, AWS, Docker, Hugging Face, Weights & Biases, OpenCV</p>
                </div>
            </section>
        </div>

        <section class="panel projects-full">
            <h2 class="panel-header">SEASON HIGHLIGHTS (KEY PROJECTS)</h2>
            <div class="project-grid">
                <div class="project-card">
                    <span class="sector-tag">SAFETY_ALIGNMENT</span>
                    <h3>LLaVA-1.5 Safety RLHF</h3><p>Mitigated layer-wise vulnerabilities in LLaVA-1.5 using RLHF and PPO on AdvBench. Applied LoRA fine-tuning on Vicuna 7B with PyTorch multi-GPU parallelism.</p>
                </div>
                <div class="project-card">
                    <span class="sector-tag">VISUAL_REASONING</span>
                    <h3>CLIP + ViT Dual-Encoder</h3><p>Architected a VQA framework in PyTorch by integrating CLIP and Vision Transformers (ViT). Achieved 46.07% accuracy on a 50K VQA v2 sample subset.</p>
                </div>
            </div>
        </section>
    </main>

    <script src="script.js"></script>
</body>
</html>